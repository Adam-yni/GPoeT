{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the device is cuda\n"
     ]
    }
   ],
   "source": [
    "from Bigram import BigramLanguageModel\n",
    "from tokenizer import tokenizer\n",
    "import torch\n",
    "\n",
    "with open('fulldata2.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of characters being used : ['\\n', ' ', '!', \"'\", ',', '-', '.', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'À', 'Á', 'Ç', 'È', 'É', 'Ê', 'Ô', 'à', 'â', 'ç', 'è', 'é', 'ê', 'ô', 'ù', 'û'] lenght of vocab : 77 number of tokens that will be created : 50\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tokenizer(text,128)\n",
    "text, vocab_size = tokenizer.initialisation()\n",
    "\n",
    "\n",
    "decoding_table, encoding_table  = tokenizer.train_BPE(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debut generation\n",
      "tensor([[  0,  47,  30,  28,  68,  37, 113,  38,  40,  43,  87,  29, 112,  68,\n",
      "          28,  33,  30,  47, 111,  49,  68,  29,  75,  40,  43,  70,  77,  68,\n",
      "          68,  68,  68,  68,  68,  68,  68,  11,  83,  44,  40,  34, 105,  63,\n",
      "          45,  92,  29,  68,  37, 113,  38,  40,  43,  45,  71,  77,  77,  14,\n",
      "          39,  68,  47,  40,  34,  87,  29, 107,  86,  37,  75,  40,  38,  27,\n",
      "         117, 127,  83,  60,  38,  83, 124,  47,  34,  44,  34,  27, 123,  59,\n",
      "          68,  37,  75,  33,  40,  38,  38,  30,  71,  77,  11,  75,  33,  40,\n",
      "          38,  38,  83, 112,  87, 127,  68,  44,  40,  37,  30, 119,  68,  29,\n",
      "          75, 127,  83,  31,  37, 111, 105,  99,  34,  68,  44,  83,  29,  63,\n",
      "          28,  33,  34,  43,  30,  70,  77,  68,  68,  68,  68,  68,  68,  68,\n",
      "          68,  11,  75,  26,  38, 101, 105, 112,  87,  45, 101,  35, 101,  43,\n",
      "          86,  39,  46,  83,  77,  11,  75,  60,  38,  83,  29, 107,  86,  37,\n",
      "          75,  40,  38,  27, 117,  29, 112,  68,  28,  34, 111,  49,  68,  44,\n",
      "          75,  92,  68,  47, 113,  31, 126,  37, 113,  39,  46,  34,  45,  71,\n",
      "          77,  11,  75,  33,  40,  38,  38,  83, 112,  87, 127,  68,  47,  92,\n",
      "          87,  44,  83,  29,  43, 112,  44,  83, 121,  44,  83,  37,  26,  38,\n",
      "          92,  45,  30,  71,  77,  68,  68,  68,  68,  68,  68,  68,  68,  11,\n",
      "          75,  33,  40,  38,  38,  83, 112,  87,  44, 111,  37,  68, 121,  37,\n",
      "         113,  38,  40,  43,  45,  71,  77,  11,  75,  33,  40,  38,  38,  83,\n",
      "         112,  87, 127,  68,  28,  40, 111, 105,  92,  68,  28,  33,  30,  38,\n",
      "         124,  68,  44,  75,  63,  37, 107,  28,  83, 121,  44,  75,  92,  47,\n",
      "          40,  37,  30,  71,  77,  11,  75,  33,  40,  38,  38,  83, 112,  87,\n",
      "         127,  68,  47,  92,  87,  44,  83,  29,  43, 112,  44,  83,  59,  68,\n",
      "          37,  75,  40,  38,  27, 117,  29, 112,  68,  28,  34, 111,  49,  71,\n",
      "          77,  68,  68,  68,  68,  68,  68,  68,  68,  11,  75,  26,  38, 101,\n",
      "         105, 112,  87, 127,  68,  28,  34, 114,  68,  27,  37, 111,  68,  77,\n",
      "          11,  75,  40,  38,  27, 117,  29, 112,  68,  31,  37, 111,  43,  86,\n",
      "          44,  75,  92,  47,  40,  37,  30,  96, 121,  37,  75,  98,  68,  47,\n",
      "          40,  34,  87,  44,  75,  63,  45,  92,  29]], device='cuda:0')\n",
      "Avec la mort des cheveux d'or,\n",
      "        Le soir étend la mort.\n",
      "\n",
      "On voit dans l'ombre une âme invisible à l'homme.\n",
      "L'homme est un soleil d'une fleur qui se déchire,\n",
      "        L'amour est toujours nue \n",
      "L'âme dans l'ombre des cieux s'en va fait la nuit.\n",
      "L'homme est un vent se dresse et se lamente.\n",
      "        L'homme est seul et la mort.\n",
      "L'homme est un coeur en chemin s'élance et s'envole.\n",
      "L'homme est un vent se dresse à l'ombre des cieux.\n",
      "        L'amour est un ciel bleu \n",
      "L'ombre des fleurs s'envole, et l'on voit s'étend\n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel(128)\n",
    "model.load_state_dict(torch.load('GPoeT.pth')) #, map_location=torch.device('cpu')\n",
    "model.eval()\n",
    "\n",
    "model.to(device)\n",
    "print('debut generation')\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "context = torch.tensor([0], dtype=torch.long, device=device).unsqueeze(1)\n",
    "generated_text = model.generate(context, max_new_tokens=400,temperature=0.1,greedy=False)\n",
    "print(generated_text)\n",
    "print(tokenizer.decode(generated_text[0].tolist(),decoding_table))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
